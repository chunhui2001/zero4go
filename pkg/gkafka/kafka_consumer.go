package gkafka

import (
	"context"
	"strings"
	"time"

	"github.com/IBM/sarama"

	. "github.com/chunhui2001/zero4go/pkg/logs"
)

// ğŸ¯ Bonusï¼šæ¶ˆè´¹è€…è¯»å– Key å’Œ Valueï¼ˆå°è£…å‡½æ•°ï¼‰
func ReadMessage(msg *sarama.ConsumerMessage) (string, string) {
	if msg.Key == nil {
		return "", string(msg.Value)
	}

	return string(msg.Key), string(msg.Value)
}

//type ConsumerHandler struct {
//	Brokers string
//	GroupId string
//	Topic   string
//	Handler func(topic string, groupId string, key string, message string) bool
//}
//
//func (h ConsumerHandler) Setup(sarama.ConsumerGroupSession) error {
//	Log.Infof("Creating consumer group: brokers=%s, topic=%s, groupId=%s", h.Brokers, h.Topic, h.GroupId)
//
//	return nil
//}
//
//func (h ConsumerHandler) Cleanup(sarama.ConsumerGroupSession) error {
//	Log.Infof("Cleanup consumer group: brokers=%s, topic=%s, groupId=%s", h.Brokers, h.Topic, h.GroupId)
//
//	return nil
//}
//
//func (h ConsumerHandler) ConsumeClaim(sess sarama.ConsumerGroupSession, claim sarama.ConsumerGroupClaim) error {
//	for msg := range claim.Messages() {
//		key, val := ReadMessage(msg)
//
//		if h.Handler(h.Topic, h.GroupId, key, val) {
//			Log.Debugf("æ¶ˆè´¹äº†ä¸€æ¡æ¶ˆæ¯[OK]: Topic=%s, groupId=%s, Key=%s, Value=%s", h.Topic, h.GroupId, key, val)
//
//			// æ‰‹åŠ¨æ ‡è®° offsetï¼ˆéå¸¸é‡è¦ï¼‰
//			sess.MarkMessage(msg, "")
//		}
//	}
//
//	return nil
//}

// ğŸ”¥ æ¶ˆè´¹è€…ç»„æœ€ä½³å®è·µï¼ˆç”Ÿäº§ç¯å¢ƒï¼‰
// âœ” 1. è‡ªåŠ¨æäº¤ offset â†’ ä¸æ¨è: å®¹æ˜“å‡ºç°é‡å¤æ¶ˆæ¯ã€‚
// âœ” 2. ä½¿ç”¨ sess.MarkMessage() æ‰‹åŠ¨æäº¤: sess.MarkMessage(msg, "")
// âœ” 3. æ¶ˆè´¹å¤±è´¥å»ºè®®å†™å…¥ é‡è¯• topicï¼ˆDLQï¼‰: main-topic â†’ retry-topic â†’ dlq-topic
// æˆ‘èƒ½å¸®ä½ ç”Ÿæˆå®Œæ•´çš„ Kafka é‡è¯•é˜Ÿåˆ— ç¤ºä¾‹ï¼ˆç”Ÿäº§çº§ï¼‰ã€‚
//func CreateConsumer(brokers string, groupId string, topic string, handler func(topic string, groupId string, key string, message string) bool) error {
//	topics := []string{topic}
//
//	config := sarama.NewConfig()
//	config.Version = sarama.V3_6_0_0
//	config.Consumer.Return.Errors = true
//	config.Consumer.Offsets.Initial = sarama.OffsetNewest
//
//	consumerGroup, err := sarama.NewConsumerGroup(strings.Split(brokers, ","), groupId, config)
//
//	if err != nil {
//		Log.Errorf("Error creating group: brokers=%s, topic=%s, groupId=%s, Error=%v", brokers, topic, groupId, err)
//
//		return err
//	}
//
//	_handler := ConsumerHandler{
//		Brokers: brokers,
//		GroupId: groupId,
//		Topic:   topic,
//		Handler: handler,
//	}
//
//	ctx := context.Background()
//
//	go func() {
//		for {
//			if err := consumerGroup.Consume(ctx, topics, _handler); err != nil {
//				log.Printf("Error from consumer: %v", err)
//			}
//		}
//	}()
//
//	// Log.Infof("Consumer started...")
//
//	return nil
//}

func CreateConsumerGroup(brokers string, groupId string, topic string, offsets int64, handler sarama.ConsumerGroupHandler) error {
	topics := []string{topic}

	config := sarama.NewConfig()
	config.Version = sarama.V3_6_0_0
	config.Consumer.Return.Errors = true
	config.Consumer.Offsets.Initial = offsets
	//config.Consumer.Offsets.Initial = sarama.OffsetNewest
	// config.Consumer.Offsets.AutoCommit.Enable = true, Sarama å®šæ—¶ commit
	config.Consumer.Group.Session.Timeout = 10 * time.Second   // å¦‚æœ broker è¿ç»­ 10 ç§’æ²¡æ”¶åˆ°å¿ƒè·³ â†’ è¸¢å‡º consumer â†’ rebalance
	config.Consumer.Group.Heartbeat.Interval = 3 * time.Second // æ¯ 3 ç§’å‘é€ä¸€æ¬¡å¿ƒè·³

	consumerGroup, err := sarama.NewConsumerGroup(strings.Split(brokers, ","), groupId, config)

	if err != nil {
		Log.Errorf("Error creating group: brokers=%s, topic=%s, groupId=%s, Error=%v", brokers, topic, groupId, err)

		return err
	}

	ctx := context.Background()

	go func() {
		for {
			if err := consumerGroup.Consume(ctx, topics, handler); err != nil {
				Log.Errorf("Error from consumer: %v", err)
			}
		}
	}()

	// Log.Infof("Consumer started...")

	return nil
}
